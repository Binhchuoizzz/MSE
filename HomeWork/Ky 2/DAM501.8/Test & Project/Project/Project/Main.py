# -*- coding: utf-8 -*-
"""
Market Basket Analysis ‚Äì Assignment Version
- ID l·∫ª  : Apriori -> Association Rules
- ID ch·∫µn: FP-Max (maximal patterns) + FP-Growth -> Association Rules
Output: out/frequent_itemsets.csv, out/association_rules.csv,
        (ID ch·∫µn) out/frequent_itemsets_maximal.csv
  |  Requires: pandas, mlxtend
"""

import os
import math
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, fpgrowth, fpmax, association_rules

# ========= CONFIG =========
FILE_PATH       = r"E:\MSE\HomeWork\Ky 2\DAM501.8\Test & Project\Project\Project\new_retail_data.csv"
INVOICE_COL     = "Transaction_ID"     # h√≥a ƒë∆°n
ITEM_COL        = "Product_Category"   # m·∫∑t h√†ng / group
ID_PARITY       = "even"                # "odd" = ID l·∫ª (Apriori) | "even" = ID ch·∫µn (FP-Max + FP-Growth)
USE_MULTI_ONLY  = True                 # B·∫≠t USE_MULTI_ONLY=True ƒë·ªÉ ch·ªâ gi·ªØ ho√° ƒë∆°n c√≥ ‚â•2 m·∫∑t h√†ng
TARGET_RANGE    = (50, 300)            # m·ª•c ti√™u s·ªë l∆∞·ª£ng lu·∫≠t ƒë·ªÉ thuy·∫øt tr√¨nh
MIN_LIFT        = 1.0                  # n·ªõi 1.0 cho dataset th∆∞a (c√≥ th·ªÉ tƒÉng 1.1+ n·∫øu nhi·ªÅu lu·∫≠t)
OUTDIR          = "out"
# ==========================

def step(msg): print(f"\nüîπ {msg}")

def load_and_clean(path: str, inv: str, item: str):
    step("Step 1: Loading dataset...")
    df = pd.read_csv(path, low_memory=False)
    print(f"‚úÖ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns.")

    step("Step 2: Cleaning & standardizing...")
    df = df[[inv, item]].dropna().copy()
    # ‚úÖ d√πng .str.strip() thay v√¨ .strip()
    df[item] = df[item].astype("string").str.strip().str.upper()
    # 1 invoice ‚Äì 1 item (lo·∫°i tr√πng)
    df = df.drop_duplicates(subset=[inv, item])
    sizes = df.groupby(inv)[item].nunique()
    multi, total = (sizes >= 2).sum(), sizes.shape[0]
    print(f"‚úÖ After clean: {len(df):,} rows | Invoices ‚â•2 items: {multi}/{total}")
    return df, sizes


def build_basket(df: pd.DataFrame, inv: str, item: str, multi_only: bool):
    step("Step 3: Building transactions...")
    if multi_only:
        keep_ids = df.groupby(inv)[item].nunique()
        keep_ids = keep_ids.index[keep_ids >= 2]
        df = df[df[inv].isin(keep_ids)].copy()

    transactions = (
        df.groupby(inv)[item]
          .apply(lambda s: sorted(set(map(str, s))))
          .tolist()
    )
    print(f"‚úÖ Built {len(transactions):,} transactions.")

    step("Step 4: Encoding transactions (one-hot)...")
    te = TransactionEncoder()
    arr = te.fit(transactions).transform(transactions)
    basket = pd.DataFrame(arr, columns=te.columns_)
    print(f"‚úÖ Encoded matrix: {basket.shape[0]} rows (transactions), {basket.shape[1]} items.")
    return basket

def mine_itemsets(basket: pd.DataFrame, algo: str, min_support: float):
    if basket.empty:
        return pd.DataFrame()
    if algo == "apriori":
        return apriori(basket, min_support=min_support, use_colnames=True)
    elif algo == "fpgrowth":
        return fpgrowth(basket, min_support=min_support, use_colnames=True)
    else:
        raise ValueError("algo must be 'apriori' or 'fpgrowth'.")

def make_rules(freq: pd.DataFrame, min_conf: float, min_lift: float):
    if freq is None or freq.empty:
        return pd.DataFrame()
    rules = association_rules(freq, metric="confidence", min_threshold=min_conf)
    base = rules.copy()
    rules = base[base["lift"] >= min_lift].copy()
    if rules.empty:
        rules = base
        return rules
    # ch·ªâ ƒë·ªÉ consequent 1 item cho d·ªÖ tr√¨nh b√†y
    rules = rules[rules["consequents"].apply(lambda s: len(s) == 1)].copy()
    # l√†m ƒë·∫πp
    rules["antecedents"] = rules["antecedents"].apply(lambda s: ", ".join(sorted(list(s))))
    rules["consequents"] = rules["consequents"].apply(lambda s: ", ".join(sorted(list(s))))
    # l·ªçc lift
    rules = rules[rules["lift"] >= min_lift].copy()
    return rules

def dynamic_grids(n_tx: int):
    """
    L∆∞·ªõi support d·ª±a tr√™n 's·ªë l·∫ßn xu·∫•t hi·ªán t·ªëi thi·ªÉu' ƒë·ªÉ ph√π h·ª£p v·ªõi s·ªë gi·ªè hi·ªán c√≥.
    """
    min_counts = [200,150,120,100,80,60,50,40,30,25,20,15,10,8,6,5,4,3,2,1]
    sup_grid = sorted({max(c / n_tx, 1 / n_tx) for c in min_counts}, reverse=True)
    #b·∫Øt bu·ªôc c√≥ lu·∫≠t - D·ªØ li·ªáu c·ª±c th∆∞a (r·∫•t √≠t ho√° ƒë∆°n c√≥ ‚â•2 m√≥n, ch·ªâ 5 category), n√™n m·ªçi c·∫∑p ch·ªâ xu·∫•t hi·ªán l√°c ƒë√°c ‚Üí confidence c·ªßa c√°c lu·∫≠t < 0.1 ‚áí 0 rules l√† b√¨nh th∆∞·ªùng
    conf_grid = [0.8,0.7,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0.02,0.01]

    #conf_grid = [0.8,0.7,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1]
    return sup_grid, conf_grid

def auto_tune_and_mine(basket: pd.DataFrame, algo: str, min_lift: float):
    """
    T·ª± ƒë·ªông t√¨m (support, confidence) cho s·ªë lu·∫≠t n·∫±m trong TARGET_RANGE.
    N·∫øu kh√¥ng ƒë·∫°t, ch·ªçn c·∫•u h√¨nh g·∫ßn nh·∫•t v·ªõi bi√™n d∆∞·ªõi ƒë·ªÉ lu·∫≠t 'g·ªçn'.
    """
    low, high = TARGET_RANGE
    sup_grid, conf_grid = dynamic_grids(basket.shape[0])

    best = (None, None, None, None, math.inf)  # freq, rules, sup, conf, score
    for sup in sup_grid:
        freq = mine_itemsets(basket, algo, sup)
        if freq is None or freq.empty:
            continue
        freq["length"] = freq["itemsets"].apply(len)
        for conf in conf_grid:
            rules = make_rules(freq, conf, min_lift)
            n = 0 if rules is None else len(rules)
            if n == 0:
                continue
            score = abs(n - low)
            if (low <= n <= high) or score < best[-1]:
                best = (freq, rules, sup, conf, score)
                if low <= n <= high:
                    return best[0], best[1], best[2], best[3]
    return best[0], best[1], best[2], best[3]

def save_and_report(freq: pd.DataFrame, rules: pd.DataFrame, parity: str, outdir: str):
    os.makedirs(outdir, exist_ok=True)
    if freq is not None and not freq.empty:
        freq.to_csv(os.path.join(outdir, "frequent_itemsets.csv"), index=False)
    else:
        pd.DataFrame(columns=["itemsets","support","length"]).to_csv(os.path.join(outdir, "frequent_itemsets.csv"), index=False)

    if rules is not None and not rules.empty:
        rules.sort_values(["lift","confidence"], ascending=False)\
             .to_csv(os.path.join(outdir, "association_rules.csv"), index=False)
    else:
        pd.DataFrame(columns=["antecedents","consequents","support","confidence","lift","leverage","conviction"]).to_csv(
            os.path.join(outdir, "association_rules.csv"), index=False
        )

    print(f"\nüì¶ Output saved in '{outdir}/'")
    print(" - frequent_itemsets.csv")
    print(" - association_rules.csv")
    if parity == "even":
        print(" - frequent_itemsets_maximal.csv (FP-Max)")

def main():
    df, sizes = load_and_clean(FILE_PATH, INVOICE_COL, ITEM_COL)

    basket = build_basket(df, INVOICE_COL, ITEM_COL, USE_MULTI_ONLY)
    n_tx, n_items = basket.shape
    if n_tx == 0 or n_items < 2:
        print("‚ùóKh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ khai th√°c. H√£y ƒë·∫∑t USE_MULTI_ONLY=False ho·∫∑c d√πng d·ªØ li·ªáu c√≥ nhi·ªÅu item h∆°n.")
        return

    if ID_PARITY == "odd":
        print("\n‚ñ∂ Thu·∫≠t to√°n: APRIORI (ID l·∫ª ‚Äì theo ƒë·ªÅ)")
        freq, rules, sup, conf = auto_tune_and_mine(basket, "apriori", MIN_LIFT)
        if freq is None or rules is None:
            # fallback: support & conf th·∫•p nh·∫•t
            sup, conf = dynamic_grids(n_tx)[0][-1], dynamic_grids(n_tx)[1][-1]
            print("‚ö†Ô∏è Auto-tune kh√¥ng ƒë·∫°t range m·ª•c ti√™u ‚Üí d√πng fallback.")
            freq = mine_itemsets(basket, "apriori", sup)
            if freq is not None and not freq.empty:
                freq["length"] = freq["itemsets"].apply(len)
            rules = make_rules(freq, conf, MIN_LIFT)

        print(f"min_support={sup:.6f} (~{round(sup*n_tx)} tx) | min_confidence={conf}")
        print(f"Frequent itemsets: {0 if freq is None else len(freq):,} | Association rules: {0 if rules is None else len(rules):,}")
        save_and_report(freq, rules, "odd", OUTDIR)

        if rules is not None and not rules.empty:
            cols = ["antecedents","consequents","support","confidence","lift","leverage","conviction"]
            print("\nTop 10 rules by lift:")
            print(rules.sort_values(["lift","confidence"], ascending=False)[cols].head(10).to_string(index=False))
        else:
            print("‚ùóCh∆∞a c√≥ lu·∫≠t. Gi·∫£m th√™m ng∆∞·ª°ng (min_lift‚Üë kh√≥, min_conf‚Üì, ho·∫∑c ƒë·∫∑t USE_MULTI_ONLY=False).")

    else:
        print("\n‚ñ∂ Thu·∫≠t to√°n: FP-MAX (maximal) + FP-GROWTH (ID ch·∫µn ‚Äì theo ƒë·ªÅ)")
        # 1) FP-Max (ƒë·ªÉ c√≥ t·∫≠p t·ªëi ƒë·∫°i)
        sup_for_max = max(1 / n_tx, 5 / n_tx)  # ƒë·ª´ng qu√° th·∫•p ƒë·ªÉ tr√°nh qu√° nhi·ªÅu pattern tr√πng
        step("Step 5a: Mining FP-Max (maximal frequent itemsets)...")
        freq_max = fpmax(basket, min_support=sup_for_max, use_colnames=True)
        if freq_max is not None and not freq_max.empty:
            freq_max["length"] = freq_max["itemsets"].apply(len)
        os.makedirs(OUTDIR, exist_ok=True)
        (freq_max if freq_max is not None else pd.DataFrame(columns=["itemsets","support","length"]))\
            .to_csv(os.path.join(OUTDIR, "frequent_itemsets_maximal.csv"), index=False)
        print(f"‚úÖ FP-Max: {0 if freq_max is None else len(freq_max):,} maximal itemsets saved.")

        # 2) FP-Growth (ƒë·ªÉ sinh lu·∫≠t)
        step("Step 5b: Mining FP-Growth (full frequent itemsets) for rules...")
        freq, rules, sup, conf = auto_tune_and_mine(basket, "fpgrowth", MIN_LIFT)
        if freq is None or rules is None:
            sup, conf = dynamic_grids(n_tx)[0][-1], dynamic_grids(n_tx)[1][-1]
            print("‚ö†Ô∏è Auto-tune kh√¥ng ƒë·∫°t range m·ª•c ti√™u ‚Üí d√πng fallback.")
            freq = mine_itemsets(basket, "fpgrowth", sup)
            if freq is not None and not freq.empty:
                freq["length"] = freq["itemsets"].apply(len)
            rules = make_rules(freq, conf, MIN_LIFT)

        print(f"min_support={sup:.6f} (~{round(sup*n_tx)} tx) | min_confidence={conf}")
        print(f"Frequent itemsets: {0 if freq is None else len(freq):,} | Association rules: {0 if rules is None else len(rules):,}")
        save_and_report(freq, rules, "even", OUTDIR)

        if rules is not None and not rules.empty:
            cols = ["antecedents","consequents","support","confidence","lift","leverage","conviction"]
            print("\nTop 10 rules by lift:")
            print(rules.sort_values(["lift","confidence"], ascending=False)[cols].head(10).to_string(index=False))
        else:
            print("‚ùóCh∆∞a c√≥ lu·∫≠t. Gi·∫£m th√™m ng∆∞·ª°ng (min_conf‚Üì) ho·∫∑c t·∫Øt USE_MULTI_ONLY ƒë·ªÉ tƒÉng m·∫´u.")

if __name__ == "__main__":
    main()
