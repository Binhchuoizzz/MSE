{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1861637f",
   "metadata": {},
   "source": [
    "# ML Strategy + Error Analysis + CNN Playbook (PyTorch)\n",
    "\n",
    "**Mục tiêu:** Notebook mẫu, gọn mà đủ xài, để bạn áp dụng nhanh 4 chủ đề:\n",
    "\n",
    "1. Chiến lược ML (metric, split, baseline),\n",
    "2. Error analysis (gom lỗi, phân loại, mismatch),\n",
    "3. CNN cơ bản (Conv/Pool/Stride + CNN nhỏ),\n",
    "4. Case studies (ResNet block, 1×1 conv, Inception-mini, Depthwise separable, MobileNet-style, Transfer Learning),\n",
    "5. EfficientNet compound scaling (minh hoạ),\n",
    "6. Chẩn đoán bias/variance & mismatch (hàm gợi ý),\n",
    "7. Random Search HPO (demo nhỏ).\n",
    "\n",
    "**Lưu ý chạy offline:** Notebook ưu tiên dùng `FakeData` nếu không có CIFAR10 cục bộ; Transfer Learning sẽ **fallback** khi không tải được trọng số pretrained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563af8a9",
   "metadata": {},
   "source": [
    "## 0) Chuẩn bị: import, seed, tiện ích\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5ce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reproducibility\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0a94b",
   "metadata": {},
   "source": [
    "## 1) ML Strategy — Single metric + Split đúng & Baseline nhanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4dd5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1A) Single metric (ví dụ F1) + ràng buộc latency (p95)\n",
    "def evaluate_with_constraints(y_true, y_pred, latencies_ms, max_p95_latency=100):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0)\n",
    "    p95_latency = float(np.percentile(latencies_ms, 95)) if len(\n",
    "        latencies_ms) > 0 else float('nan')\n",
    "    ok_latency = (p95_latency <= max_p95_latency) if not math.isnan(\n",
    "        p95_latency) else False\n",
    "    return {\"acc\": acc, \"precision\": p, \"recall\": r, \"f1\": f1,\n",
    "            \"p95_latency_ms\": p95_latency, \"latency_ok\": bool(ok_latency)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2482977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 không sẵn, dùng FakeData thay thế: Dataset not found or corrupted. You can use download=True to download it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16000, 2000, 2000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1B) Dataset loader: ưu tiên CIFAR10 cục bộ; fallback FakeData (offline-friendly)\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    try:\n",
    "        # Không tải từ internet: chỉ dùng nếu đã có sẵn\n",
    "        ds = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                              download=False, transform=transform)\n",
    "    except Exception as e:\n",
    "        print(\"CIFAR10 không sẵn, dùng FakeData thay thế:\", e)\n",
    "        ds = datasets.FakeData(size=20000, image_size=(\n",
    "            3, 224, 224), num_classes=10, transform=transform)\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds = load_dataset()\n",
    "n = len(ds)\n",
    "n_train = int(0.8*n)\n",
    "n_dev = int(0.1*n)\n",
    "n_test = n - n_train - n_dev\n",
    "train_ds, dev_ds, test_ds = random_split(\n",
    "    ds, [n_train, n_dev, n_test], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
    "                          num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "dev_loader = DataLoader(dev_ds,   batch_size=128, shuffle=False,\n",
    "                        num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "test_loader = DataLoader(test_ds,  batch_size=128, shuffle=False,\n",
    "                         num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "len(train_ds), len(dev_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a8e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.1045,\n",
       " 'precision': 0.01045,\n",
       " 'recall': 0.1,\n",
       " 'f1': 0.01892258940697148,\n",
       " 'p95_latency_ms': 6.576061248779297,\n",
       " 'latency_ok': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1C) Baseline nhanh (linear head trên mean RGB) + vòng lặp train/eval\n",
    "class BaselineLinear(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(3, num_classes)  # 3 kênh RGB -> num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)  # [B,3]\n",
    "        return self.fc(x)  # logits\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, opt, device):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += yb.size(0)\n",
    "        correct += (logits.argmax(1) == yb).sum().item()\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    yh = []\n",
    "    lat = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            t0 = time.time()\n",
    "            logits = model(xb)\n",
    "            t1 = time.time()\n",
    "            ys.extend(yb.cpu().numpy())\n",
    "            yh.extend(logits.argmax(1).cpu().numpy())\n",
    "            lat.extend([(t1-t0)*1000]*yb.size(0))\n",
    "    return evaluate_with_constraints(np.array(ys), np.array(yh), np.array(lat))\n",
    "\n",
    "\n",
    "baseline = BaselineLinear(num_classes=10).to(device)\n",
    "opt = torch.optim.Adam(baseline.parameters(), lr=1e-3)\n",
    "for _ in range(1):  # baseline rất nhanh\n",
    "    train_one_epoch(baseline, train_loader, opt, device)\n",
    "dev_metrics = evaluate(baseline, dev_loader, device)\n",
    "dev_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b27225",
   "metadata": {},
   "source": [
    "## 2) Error Analysis — Gom lỗi, phân loại nguyên nhân, kiểm tra mismatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,\n",
       " [np.int64(0),\n",
       "  np.int64(1),\n",
       "  np.int64(2),\n",
       "  np.int64(3),\n",
       "  np.int64(4),\n",
       "  np.int64(5),\n",
       "  np.int64(6),\n",
       "  np.int64(7),\n",
       "  np.int64(8),\n",
       "  np.int64(9)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2A) Thu lỗi trên dev (giữ index để soi)\n",
    "def collect_errors(model, dataset, device, max_items=200):\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    model.eval()\n",
    "    wrong = []\n",
    "    with torch.no_grad():\n",
    "        offset = 0\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb).argmax(1)\n",
    "            mism = (pred != yb).nonzero(\n",
    "                as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "            for i in mism:\n",
    "                wrong.append(offset+i)\n",
    "                if len(wrong) >= max_items:\n",
    "                    return wrong\n",
    "            offset += yb.size(0)\n",
    "    return wrong\n",
    "\n",
    "\n",
    "wrong_idx = collect_errors(baseline, dev_ds, device, max_items=120)\n",
    "len(wrong_idx), wrong_idx[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f688d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'other': (120, 1.0)}, 120)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2B) Gán nhãn loại lỗi (demo heuristic: tối/sáng/quá giống) & breakdown %\n",
    "def brightness(img_tensor):  # img [3,H,W] in [0,1]\n",
    "    return img_tensor.mean().item()\n",
    "\n",
    "\n",
    "def categorize_error(img, label, pred):\n",
    "    b = brightness(img)\n",
    "    if b < 0.28:\n",
    "        return \"too_dark\"\n",
    "    if b > 0.75:\n",
    "        return \"too_bright\"\n",
    "    if label in [3, 5] and pred in [3, 5]:\n",
    "        return \"confused_similar_classes\"\n",
    "    return \"other\"\n",
    "\n",
    "\n",
    "def error_breakdown(model, dataset, wrong_idx, device):\n",
    "    cat = Counter()\n",
    "    loader = DataLoader(Subset(dataset, wrong_idx),\n",
    "                        batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (xb, yb) in loader:\n",
    "            img = xb[0]\n",
    "            pred = model(xb.to(device)).argmax(1).item()\n",
    "            cat[categorize_error(img, yb.item(), pred)] += 1\n",
    "    total = sum(cat.values()) if len(cat) > 0 else 1\n",
    "    return {k: (v, v/total) for k, v in cat.items()}, total\n",
    "\n",
    "\n",
    "cats, total_err = error_breakdown(baseline, dev_ds, wrong_idx, device)\n",
    "cats, total_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad7fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train_dev': 0.1045,\n",
       " 'acc_dev': 0.1045,\n",
       " 'hint': 'Nếu dev << train-dev ⇒ dev khác phân phối train (mismatch)'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2C) Kiểm tra mismatch: training-dev (lấy mẫu từ train) vs dev\n",
    "train_dev_ds = Subset(train_ds, np.random.choice(\n",
    "    len(train_ds), size=min(2000, len(train_ds)), replace=False))\n",
    "\n",
    "\n",
    "def quick_acc(model, dataset):\n",
    "    ld = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "    model.eval()\n",
    "    y = []\n",
    "    p = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in ld:\n",
    "            y.extend(yb.numpy())\n",
    "            p.extend(model(xb.to(device)).argmax(1).cpu().numpy())\n",
    "    return accuracy_score(y, p)\n",
    "\n",
    "\n",
    "acc_train_dev = quick_acc(baseline, train_dev_ds)\n",
    "acc_dev = quick_acc(baseline, dev_ds)\n",
    "{\"acc_train_dev\": acc_train_dev, \"acc_dev\": acc_dev,\n",
    "    \"hint\": \"Nếu dev << train-dev ⇒ dev khác phân phối train (mismatch)\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb98f0",
   "metadata": {},
   "source": [
    "## 3) CNN cơ bản — Conv/Stride/Padding/Pooling & CNN nhỏ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.094,\n",
       " 'precision': 0.0094,\n",
       " 'recall': 0.1,\n",
       " 'f1': 0.017184643510054845,\n",
       " 'p95_latency_ms': 754.4708251953125,\n",
       " 'latency_ok': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=3, s=1, p='same'):\n",
    "        super().__init__()\n",
    "        pad = k//2 if p == 'same' else 0\n",
    "        self.conv = nn.Conv2d(c_in, c_out, kernel_size=k,\n",
    "                              stride=s, padding=pad, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            ConvBlock(3, 32), ConvBlock(32, 32), nn.MaxPool2d(2),  # H/2\n",
    "            ConvBlock(32, 64), ConvBlock(64, 64), nn.MaxPool2d(2),  # H/4\n",
    "            ConvBlock(64, 128), nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.head = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x).squeeze(-1).squeeze(-1)\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "cnn = TinyCNN().to(device)\n",
    "opt = torch.optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "for _ in range(1):\n",
    "    train_one_epoch(cnn, train_loader, opt, device)\n",
    "evaluate(cnn, dev_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a19be",
   "metadata": {},
   "source": [
    "## 4) Case studies — ResNet block, 1×1 conv, Inception-mini, Depthwise/MobileNet, Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38415112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Admin/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 68.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5130"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4A) Residual Block (ResNet)\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            c_in, c_out, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c_out)\n",
    "        self.conv2 = nn.Conv2d(c_out, c_out, 3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or c_in != c_out:\n",
    "            self.skip = nn.Sequential(nn.Conv2d(c_in, c_out, 1, stride=stride, bias=False),\n",
    "                                      nn.BatchNorm2d(c_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.act(out + identity)\n",
    "        return out\n",
    "\n",
    "# 4B) 1×1 Convolution\n",
    "\n",
    "\n",
    "class Conv1x1(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "\n",
    "    def forward(self, x): return F.relu(self.bn(self.conv(x)), inplace=True)\n",
    "\n",
    "# 4C) Inception mini\n",
    "\n",
    "\n",
    "class InceptionMini(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        c = c_out//4\n",
    "        self.b1 = nn.Sequential(Conv1x1(c_in, c), nn.Conv2d(\n",
    "            c, c, 3, padding=1), nn.ReLU(True))\n",
    "        self.b2 = nn.Sequential(Conv1x1(c_in, c), nn.Conv2d(\n",
    "            c, c, 5, padding=2), nn.ReLU(True))\n",
    "        self.b3 = nn.Sequential(nn.MaxPool2d(\n",
    "            3, stride=1, padding=1), Conv1x1(c_in, c))\n",
    "        self.b4 = Conv1x1(c_in, c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], dim=1)\n",
    "\n",
    "# 4D) Depthwise separable conv (MobileNet-style)\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(c_in, c_in, 3, stride=stride,\n",
    "                            padding=1, groups=c_in, bias=False)\n",
    "        self.pw = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c_in)\n",
    "        self.bn2 = nn.BatchNorm2d(c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.dw(x)), inplace=True)\n",
    "        x = F.relu(self.bn2(self.pw(x)), inplace=True)\n",
    "        return x\n",
    "\n",
    "# 4E) MobileNetV2 Inverted Residual (rút gọn)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1, expand=6):\n",
    "        super().__init__()\n",
    "        hidden = c_in * expand\n",
    "        self.use_skip = (stride == 1 and c_in == c_out)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(c_in, hidden, 1, bias=False), nn.BatchNorm2d(\n",
    "                hidden), nn.ReLU6(True),\n",
    "            nn.Conv2d(hidden, hidden, 3, stride=stride,\n",
    "                      padding=1, groups=hidden, bias=False),\n",
    "            nn.BatchNorm2d(hidden), nn.ReLU6(True),\n",
    "            nn.Conv2d(hidden, c_out, 1, bias=False), nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return x+out if self.use_skip else out\n",
    "\n",
    "# 4F) Transfer learning với ResNet18 (fallback nếu không tải được pretrained)\n",
    "\n",
    "\n",
    "def transfer_learning_resnet18(num_classes=10, freeze_backbone=True):\n",
    "    try:\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    except Exception as e:\n",
    "        print(\"Không tải được trọng số pretrained, dùng weights=None. Lý do:\", e)\n",
    "        model = models.resnet18(weights=None)\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "    in_feat = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feat, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Demo init (không train lâu để tiết kiệm thời gian)\n",
    "ft_model = transfer_learning_resnet18(\n",
    "    num_classes=10, freeze_backbone=True).to(device)\n",
    "sum(p.numel() for p in ft_model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ceb20",
   "metadata": {},
   "source": [
    "## 5) EfficientNet — Compound scaling (minh hoạ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi=0 -> (channels,width,depth,res)=(32, 4, 128)\n",
      "phi=1 -> (channels,width,depth,res)=(35, 5, 147)\n",
      "phi=2 -> (channels,width,depth,res)=(38, 6, 169)\n",
      "phi=3 -> (channels,width,depth,res)=(42, 7, 194)\n"
     ]
    }
   ],
   "source": [
    "def compound_scale(base_channels=32, base_depth=4, base_res=128, phi=1, alpha=1.2, beta=1.1, gamma=1.15):\n",
    "    C = int(base_channels * (beta ** phi))      # width\n",
    "    D = int(round(base_depth * (alpha ** phi)))  # depth\n",
    "    R = int(base_res * (gamma ** phi))          # resolution\n",
    "    return C, D, R\n",
    "\n",
    "\n",
    "for phi in range(4):\n",
    "    print(f\"phi={phi} -> (channels,width,depth,res)={compound_scale(phi=phi)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55c50c",
   "metadata": {},
   "source": [
    "## 6) Chẩn đoán & khuyến nghị (bias/variance & mismatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270494bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High bias so với mức người: tăng capacity (ResNet sâu hơn), train lâu hơn, LR schedule.',\n",
       " 'Data mismatch: dev khác train; thu thập thêm dữ liệu giống dev hoặc synth điều kiện dev.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diagnose_and_recommend(train_acc, dev_acc, human_acc=None, train_dev_acc=None):\n",
    "    tips = []\n",
    "    if human_acc is not None and train_acc < human_acc - 0.05:\n",
    "        tips.append(\n",
    "            \"High bias so với mức người: tăng capacity (ResNet sâu hơn), train lâu hơn, LR schedule.\")\n",
    "    if train_acc > 0.95 and dev_acc < 0.85:\n",
    "        tips.append(\n",
    "            \"High variance: thêm dữ liệu cùng phân phối dev, L2/Dropout/augment, giảm model.\")\n",
    "    if train_dev_acc is not None and (train_dev_acc - dev_acc) > 0.1:\n",
    "        tips.append(\n",
    "            \"Data mismatch: dev khác train; thu thập thêm dữ liệu giống dev hoặc synth điều kiện dev.\")\n",
    "    if not tips:\n",
    "        tips.append(\n",
    "            \"Ổn: tiếp tục HPO (random search log-scale), tinh chỉnh threshold/latency.\")\n",
    "    return tips\n",
    "\n",
    "\n",
    "diagnose_and_recommend(train_acc=0.92, dev_acc=0.80,\n",
    "                       human_acc=0.98, train_dev_acc=0.91)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd947d",
   "metadata": {},
   "source": [
    "## 7) Random Search HPO (log-scale LR, weight decay, dropout) — demo nhỏ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b93b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.102,\n",
       " {'lr': 0.0011605429165440168,\n",
       "  'weight_decay': 7.531309895034413e-06,\n",
       "  'p_drop': 0.42788865089209005})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, d_in=3*7*7, hidden=256, num_classes=10, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(d_in, hidden), nn.ReLU(True), nn.Dropout(p_drop),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "\n",
    "def sample_hparams():\n",
    "    lr = 10 ** np.random.uniform(-4, -2)           # [1e-4, 1e-2]\n",
    "    weight_decay = 10 ** np.random.uniform(-6, -3)  # [1e-6, 1e-3]\n",
    "    p_drop = np.random.uniform(0.1, 0.6)\n",
    "    return dict(lr=lr, weight_decay=weight_decay, p_drop=p_drop)\n",
    "\n",
    "\n",
    "# tạo feature nhỏ từ ảnh để HPO nhanh (giảm chi phí)\n",
    "shrink = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "\n",
    "def run_trial(model_ctor, train_loader, dev_loader, max_epochs=2):\n",
    "    hp = sample_hparams()\n",
    "    model = model_ctor(p_drop=hp['p_drop']).to(device)\n",
    "    opt = torch.optim.Adam(\n",
    "        model.parameters(), lr=hp['lr'], weight_decay=hp['weight_decay'])\n",
    "    # train ngắn\n",
    "    for _ in range(max_epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            xb = shrink(xb).to(device)\n",
    "            yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = nn.CrossEntropyLoss()(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    # eval\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    yh = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dev_loader:\n",
    "            ys.extend(yb.numpy())\n",
    "            yh.extend(model(shrink(xb).to(device)).argmax(1).cpu().numpy())\n",
    "    acc = accuracy_score(ys, yh)\n",
    "    return acc, hp\n",
    "\n",
    "\n",
    "best = (-1, None)\n",
    "for t in range(3):  # demo 3 trials\n",
    "    acc, hp = run_trial(lambda p_drop: MLPHead(p_drop=p_drop),\n",
    "                        train_loader, dev_loader, max_epochs=1)\n",
    "    if acc > best[0]:\n",
    "        best = (acc, hp)\n",
    "best\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
