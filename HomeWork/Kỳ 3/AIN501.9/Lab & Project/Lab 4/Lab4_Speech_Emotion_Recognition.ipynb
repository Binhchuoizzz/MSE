{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 — Speech Emotion Recognition (SER)\n",
    "\n",
    "Notebook này triển khai pipeline đầy đủ cho SER sử dụng Python, Librosa và TensorFlow/Keras. Bạn có thể chạy trên Google Colab (khuyến nghị) hoặc máy cá nhân có GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mục tiêu & Deliverables\n",
    "\n",
    "- Tiền xử lý audio (chuẩn hóa, cắt/pad, tăng cường dữ liệu)\n",
    "- Trích xuất đặc trưng (log-mel spectrogram, MFCC + delta)\n",
    "- Huấn luyện mô hình CNN + BiLSTM phân loại cảm xúc\n",
    "- Đánh giá: accuracy, classification report, confusion matrix\n",
    "- Suy luận (inference) với file `.wav` của bạn\n",
    "- Xuất model `.h5` và lưu các biểu đồ loss/accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nếu chạy trên Colab, nên bật GPU: Runtime -> Change runtime type -> GPU\n",
    "import librosa.display\n",
    "import librosa\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import pathlib\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cài đặt thư viện cần thiết\n",
    "\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split(\"==\")[0].split(\">=\")[0].split(\"<=\")[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "\n",
    "for pkg in [\n",
    "    \"librosa>=0.10.1\",\n",
    "    \"soundfile\",\n",
    "    \"matplotlib\",\n",
    "    \"scikit-learn\",\n",
    "    \"tensorflow>=2.13\",\n",
    "    \"tqdm\",\n",
    "]:\n",
    "    pip_install(pkg)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dữ liệu\n",
    "\n",
    "Notebook hỗ trợ **RAVDESS** và **EmoDB**. Do vấn đề bản quyền/phân phối, bạn tự chuẩn bị dữ liệu.\n",
    "\n",
    "**Tùy chọn A (khuyên dùng):** tải dữ liệu về Google Drive rồi chỉ đường dẫn.\n",
    "\n",
    "**Tùy chọn B (demo nhanh):** đặt một thư mục `datasets/sample` chứa vài file `.wav` theo cấu trúc:\n",
    "\n",
    "```\n",
    "datasets/\n",
    "  ravdess/Audio_Speech_Actors_01-24/... (các file .wav)\n",
    "  emodb/wav/... (các file .wav)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định cấu hình đường dẫn dữ liệu ở đây\n",
    "DATA_DIRS = {\n",
    "    \"ravdess\": \"/content/datasets/ravdess\",  # thay bằng đường dẫn của bạn\n",
    "    \"emodb\":   \"/content/datasets/emodb\",    # thay bằng đường dẫn của bạn\n",
    "}\n",
    "\n",
    "# Nếu bạn dùng Jupyter local, có thể thay /content bằng đường dẫn máy bạn.\n",
    "# Với Colab + Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DATA_DIRS[\"ravdess\"] = \"/content/drive/MyDrive/datasets/ravdess\"\n",
    "# DATA_DIRS[\"emodb\"] = \"/content/drive/MyDrive/datasets/emodb\"\n",
    "\n",
    "for k, v in DATA_DIRS.items():\n",
    "    print(f\"{k}: {v} -> {'OK' if os.path.isdir(v) else 'MISSING'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping nhãn cảm xúc\n",
    "\n",
    "RAVDESS mã hóa cảm xúc trong tên file (thẻ `-XX-`), EmoDB dùng ký hiệu chữ cái. Bảng mapping sau chuẩn hóa về 7 lớp:\n",
    "`neutral, calm, happy, sad, angry, fearful, disgust` (có thể không đủ trên mọi bộ dữ liệu; ta sẽ tự động gộp khi thiếu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAVDESS_EMO_MAP = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"  # có thể loại bỏ nếu không muốn\n",
    "}\n",
    "\n",
    "# EmoDB: (Berlin) codes in filename like 'xxxyy.wav' with emotion letter at position 5\n",
    "EMODB_MAP = {\n",
    "    \"W\": \"angry\",\n",
    "    \"L\": \"boredom\",   # có thể gộp vào 'neutral'\n",
    "    \"E\": \"disgust\",\n",
    "    \"A\": \"fearful\",\n",
    "    \"F\": \"happy\",\n",
    "    \"T\": \"sad\",\n",
    "    \"N\": \"neutral\"\n",
    "}\n",
    "\n",
    "TARGET_LABELS = [\"neutral\", \"calm\", \"happy\",\n",
    "                 \"sad\", \"angry\", \"fearful\", \"disgust\"]\n",
    "CANONICAL = {  # gộp label ngoài chuẩn vào nhãn gần nhất\n",
    "    \"boredom\": \"neutral\",\n",
    "    \"surprised\": \"happy\"  # thay đổi nếu bạn muốn giữ 'surprised' riêng\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "\n",
    "def parse_emotion_from_ravdess(path):\n",
    "    # RAVDESS: filename like '03-01-05-01-02-01-12.wav' -> the 3rd group is emotion code\n",
    "    m = re.search(r\"(\\d+)-(\\d+)-(\\d+)-\", os.path.basename(path))\n",
    "    if not m:\n",
    "        return None\n",
    "    emo_code = m.group(3)\n",
    "    return RAVDESS_EMO_MAP.get(emo_code)\n",
    "\n",
    "\n",
    "def parse_emotion_from_emodb(path):\n",
    "    # EmoDB: filename like '03a01Fa.wav' -> letter at position 6 is emotion\n",
    "    base = os.path.basename(path)\n",
    "    m = re.search(r\"([A-Za-z])\\d?\\.wav$\", base)\n",
    "    # Safer parse: find the first capital letter among {W,L,E,A,F,T,N}\n",
    "    for ch in base:\n",
    "        if ch.upper() in EMODB_MAP:\n",
    "            return EMODB_MAP[ch.upper()]\n",
    "    return None\n",
    "\n",
    "\n",
    "def canonicalize(label):\n",
    "    return CANONICAL.get(label, label)\n",
    "\n",
    "\n",
    "rows = []\n",
    "for ds, root in DATA_DIRS.items():\n",
    "    if not os.path.isdir(root):\n",
    "        continue\n",
    "    pattern = \"**/*.wav\"\n",
    "    for p in glob.glob(os.path.join(root, pattern), recursive=True):\n",
    "        emo = None\n",
    "        if ds == \"ravdess\":\n",
    "            emo = parse_emotion_from_ravdess(p)\n",
    "        elif ds == \"emodb\":\n",
    "            emo = parse_emotion_from_emodb(p)\n",
    "        if emo:\n",
    "            rows.append({\"path\": p, \"dataset\": ds,\n",
    "                        \"emotion_raw\": emo, \"emotion\": canonicalize(emo)})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Total files:\", len(df))\n",
    "print(df.emotion.value_counts())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trích xuất đặc trưng\n",
    "\n",
    "Ta dùng **log-mel spectrogram** hình ảnh thời gian–tần số cố định để huấn luyện CNN+BiLSTM. Thêm MFCC + delta làm kênh phụ (tùy chọn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000            # sample rate\n",
    "DURATION = 3.0        # giây, mỗi mẫu sẽ pad/trim về cố định\n",
    "N_MELS = 64\n",
    "N_FFT = 1024\n",
    "HOP_LEN = 256\n",
    "\n",
    "\n",
    "def load_wav(path, sr=SR, duration=DURATION):\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    target_len = int(sr * duration)\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "    return y\n",
    "\n",
    "\n",
    "def extract_features(y, sr=SR):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LEN, n_mels=N_MELS)\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    d_mfcc = librosa.feature.delta(mfcc)\n",
    "    dd_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    # Chuẩn hóa theo trục thời gian\n",
    "\n",
    "    def norm(x):\n",
    "        mu = np.mean(x, axis=1, keepdims=True)\n",
    "        sd = np.std(x, axis=1, keepdims=True) + 1e-9\n",
    "        return (x - mu)/sd\n",
    "    return norm(logmel), norm(mfcc), norm(d_mfcc), norm(dd_mfcc)\n",
    "\n",
    "\n",
    "# Demo 1 file nếu có\n",
    "if len(df) > 0:\n",
    "    y = load_wav(df.iloc[0][\"path\"])\n",
    "    logmel, *_ = extract_features(y)\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    librosa.display.specshow(\n",
    "        logmel, sr=SR, hop_length=HOP_LEN, x_axis=\"time\", y_axis=\"mel\")\n",
    "    plt.title(\"Log-mel spectrogram (demo)\")\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(frame: pd.DataFrame):\n",
    "    X_mel, X_mfcc, X_d1, X_d2, y = [], [], [], [], []\n",
    "    for _, r in tqdm(frame.iterrows(), total=len(frame)):\n",
    "        try:\n",
    "            y_wav = load_wav(r[\"path\"])\n",
    "            mel, mfcc, d1, d2 = extract_features(y_wav)\n",
    "            # Đưa về shape (T, F, C)\n",
    "            mel = mel.T[:, :, None]\n",
    "            # Có thể concatenate MFCC/deltas theo kênh nếu muốn\n",
    "            X_mel.append(mel.astype(np.float32))\n",
    "            y.append(r[\"emotion\"])\n",
    "        except Exception as e:\n",
    "            print(\"Skip\", r[\"path\"], e)\n",
    "    X = np.stack(X_mel)\n",
    "    label2id = {lab: i for i, lab in enumerate(sorted(frame.emotion.unique()))}\n",
    "    y_ids = np.array([label2id[v] for v in y])\n",
    "    id2label = {i: lab for lab, i in label2id.items()}\n",
    "    return X, y_ids, label2id, id2label\n",
    "\n",
    "\n",
    "# Lọc chỉ những label có đủ tối thiểu số lượng mẫu\n",
    "MIN_PER_CLASS = 20\n",
    "vc = df.emotion.value_counts()\n",
    "valid_labels = set(vc[vc >= MIN_PER_CLASS].index)\n",
    "df_f = df[df.emotion.isin(valid_labels)].copy()\n",
    "print(\"Giữ\", len(valid_labels), \"nhãn:\",\n",
    "      valid_labels, \" | Số file:\", len(df_f))\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_f, test_size=0.2, random_state=42, stratify=df_f[\"emotion\"])\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, test_size=0.2, random_state=42, stratify=train_df[\"emotion\"])\n",
    "\n",
    "print(\"Train/Val/Test:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "X_train, y_train, label2id, id2label = build_arrays(train_df)\n",
    "X_val, y_val, _, _ = build_arrays(val_df)\n",
    "X_test, y_test, _, _ = build_arrays(test_df)\n",
    "\n",
    "num_classes = len(label2id)\n",
    "input_shape = X_train.shape[1:]  # (T, F, C)\n",
    "input_shape, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô hình: CNN + BiLSTM\n",
    "\n",
    "Kiến trúc gọn nhẹ nhưng hiệu quả cho SER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    # Collapse frequency dim, keep time dim\n",
    "    # Shape now: (T/4, F/4, 64)\n",
    "    t = tf.shape(x)[1]\n",
    "    f = x.shape[2]\n",
    "    c = x.shape[3]\n",
    "    x = layers.Reshape((-1, f*c))(x)  # (T', F'*C)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=False))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_model(input_shape, num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights để xử lý mất cân bằng\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.arange(num_classes)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                     classes=classes,\n",
    "                                     y=y_train)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"class_weights:\", class_weights)\n",
    "\n",
    "ckpt_path = \"best_model.keras\"\n",
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        ckpt_path, monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=6, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ learning curves\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss curve\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá trên test set\n",
    "pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"Accuracy (test):\", np.mean(pred == y_test))\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, pred, target_names=[\n",
    "      id2label[i] for i in range(num_classes)]))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred, labels=list(range(num_classes)))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\n",
    "                              id2label[i] for i in range(num_classes)])\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(ax=ax, xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suy luận với file .wav của bạn\n",
    "def predict_wav(path):\n",
    "    y = load_wav(path)\n",
    "    mel, *_ = extract_features(y)\n",
    "    x = mel.T[None, :, :, None].astype(np.float32)\n",
    "    probs = model.predict(x)[0]\n",
    "    for i, p in enumerate(probs):\n",
    "        print(f\"{id2label[i]:<10}: {p:.3f}\")\n",
    "    print(\"=> Dự đoán:\", id2label[int(np.argmax(probs))])\n",
    "\n",
    "# Ví dụ:\n",
    "# predict_wav(\"/content/some_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "model.save(\"ser_cnn_bilstm.h5\")\n",
    "print(\"Saved ser_cnn_bilstm.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ghi chú\n",
    "\n",
    "- Nếu dữ liệu quá ít, hãy giảm `DURATION` hoặc tăng cường dữ liệu.\n",
    "- Có thể thêm SpecAugment (masking theo thời gian/tần số) để tăng robustness.\n",
    "- Thử các kiến trúc khác (CNN-only, CRNN sâu hơn, AST/transformer) nếu bạn có GPU mạnh.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab4_Speech_Emotion_Recognition.ipynb"
  },
  "kernelspec": {
   "display_name": "myenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
