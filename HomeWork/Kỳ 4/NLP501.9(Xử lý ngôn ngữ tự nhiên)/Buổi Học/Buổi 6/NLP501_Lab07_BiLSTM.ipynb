{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb8bf61",
   "metadata": {},
   "source": [
    "# Lab 07-03: Sentiment Analysis with Bidirectional LSTM\n",
    "\n",
    "**Dataset:** IMDB Movie Reviews (25,000 training + 25,000 test)  \n",
    "**Task:** Binary classification (Positive/Negative sentiment)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaceffb3",
   "metadata": {},
   "source": [
    "## Part 1: Setup và Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Set random seed\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c174b1",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download và load IMDB dataset (copy from solution notebook)\n",
    "def download_imdb_dataset(data_dir='./data'):\n",
    "    \"\"\"Download IMDB dataset\"\"\"\n",
    "    url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "    filepath = os.path.join(data_dir, \"aclImdb_v1.tar.gz\")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(data_dir, 'aclImdb')):\n",
    "        print(\"Downloading IMDB dataset...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        print(\"Extracting...\")\n",
    "        with tarfile.open(filepath, 'r:gz') as tar:\n",
    "            tar.extractall(data_dir)\n",
    "        os.remove(filepath)\n",
    "        print(\" Done!\")\n",
    "    else:\n",
    "        print(\" Dataset already exists.\")\n",
    "    \n",
    "    return os.path.join(data_dir, 'aclImdb')\n",
    "\n",
    "def load_imdb_data(data_path, split='train'):\n",
    "    \"\"\"Load IMDB data\"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_type in ['pos', 'neg']:\n",
    "        dir_path = os.path.join(data_path, split, label_type)\n",
    "        label = 1 if label_type == 'pos' else 0\n",
    "        \n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(dir_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    texts.append(f.read())\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return texts, labels\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'[^a-z0-9\\\\s]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Download and load data\n",
    "data_path = download_imdb_dataset()\n",
    "print(\"\\\\nLoading data...\")\n",
    "train_texts, train_labels = load_imdb_data(data_path, 'train')\n",
    "test_texts, test_labels = load_imdb_data(data_path, 'test')\n",
    "print(f\" Train: {len(train_texts)}, Test: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary (copy from solution)\n",
    "class Vocabulary:\n",
    "    \"\"\"Vocabulary class\"\"\"\n",
    "    \n",
    "    def __init__(self, max_vocab_size=25000, min_freq=2):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.min_freq = min_freq\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "        self.word_freq = Counter()\n",
    "        \n",
    "    def build_vocab(self, texts):\n",
    "        \"\"\"Build vocabulary\"\"\"\n",
    "        print(\"Building vocabulary...\")\n",
    "        for text in tqdm(texts):\n",
    "            tokens = preprocess_text(text)\n",
    "            self.word_freq.update(tokens)\n",
    "        \n",
    "        filtered_words = [\n",
    "            word for word, freq in self.word_freq.items() \n",
    "            if freq >= self.min_freq\n",
    "        ]\n",
    "        \n",
    "        sorted_words = sorted(filtered_words, key=lambda w: self.word_freq[w], reverse=True)\n",
    "        vocab_words = sorted_words[:self.max_vocab_size - 2]\n",
    "        \n",
    "        for idx, word in enumerate(vocab_words, start=2):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "        \n",
    "        print(f\"✓ Vocabulary: {len(self.word2idx):,} words\")\n",
    "    \n",
    "    def text_to_indices(self, text):\n",
    "        \"\"\"Convert text to indices\"\"\"\n",
    "        tokens = preprocess_text(text)\n",
    "        indices = [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = Vocabulary(max_vocab_size=25000, min_freq=2)\n",
    "vocab.build_vocab(train_texts)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3848cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "class IMDBDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for IMDB\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, vocab, max_length=256):\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.sequences = []\n",
    "        for text in tqdm(texts, desc=\"Converting texts\"):\n",
    "            indices = vocab.text_to_indices(text)\n",
    "            if len(indices) > max_length:\n",
    "                indices = indices[:max_length]\n",
    "            self.sequences.append(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.sequences[idx], dtype=torch.long),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function\"\"\"\n",
    "    sequences, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_sequences, labels, lengths\n",
    "\n",
    "# Create datasets\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = IMDBDataset(train_texts, train_labels, vocab, MAX_LENGTH)\n",
    "test_dataset = IMDBDataset(test_texts, test_labels, vocab, MAX_LENGTH)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\" Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1687a",
   "metadata": {},
   "source": [
    "## Part 3: BiLSTM Model\n",
    "\n",
    "### 3.1. BiLSTM Architecture\n",
    "\n",
    "Key differences from unidirectional LSTM:\n",
    "1. **bidirectional=True** trong nn.LSTM\n",
    "2. **hidden_dim * 2** for FC layer (because we have forward + backward)\n",
    "3. **Concatenate forward và backward hidden states**: `torch.cat((hidden[-2], hidden[-1]), dim=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM for Sentiment Classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
    "                 n_layers=2, dropout=0.5, pad_idx=0):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        # Bidirectional LSTM \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,  #  KEY: Enable bidirectional\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # FC layer: input = hidden_dim * 2 (vì bidirectional) \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            text: [batch_size, seq_len]\n",
    "            text_lengths: [batch_size]\n",
    "        \n",
    "        Returns:\n",
    "            output: [batch_size]\n",
    "        \"\"\"\n",
    "        # Embedding: [batch_size, seq_len, embedding_dim]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # Pack padded sequence\n",
    "        packed_embedded = pack_padded_sequence(\n",
    "            embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # BiLSTM\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # hidden: [n_layers * 2, batch_size, hidden_dim]\n",
    "        # Note: *2 because bidirectional\n",
    "        \n",
    "        # Concatenate forward and backward hidden states \n",
    "        # Forward: hidden[-2], Backward: hidden[-1]\n",
    "        final_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        # final_hidden: [batch_size, hidden_dim * 2]\n",
    "        \n",
    "        # Dropout + FC + Sigmoid\n",
    "        output = self.dropout(final_hidden)\n",
    "        output = self.fc(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output.squeeze(1)\n",
    "\n",
    "# Model hyperparameters\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = vocab.word2idx['<PAD>']\n",
    "\n",
    "# Create BiLSTM model\n",
    "bilstm_model = BiLSTMClassifier(\n",
    "    VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "    N_LAYERS, DROPOUT, PAD_IDX\n",
    ").to(device)\n",
    "\n",
    "print(\"BiLSTM Model\")\n",
    "print(bilstm_model)\n",
    "print(f\"\\\\nTotal parameters: {sum(p.numel() for p in bilstm_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65720bb8",
   "metadata": {},
   "source": [
    "## Part 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1428f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions (copy from solution)\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        sequences, labels, lengths = batch\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(sequences, lengths)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        predicted_labels = (predictions >= 0.5).float()\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return epoch_loss / len(dataloader), correct / total\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            sequences, labels, lengths = batch\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            predictions = model(sequences, lengths)\n",
    "            loss = criterion(predictions, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            predicted_labels = (predictions >= 0.5).float()\n",
    "            all_preds.extend(predicted_labels.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss / len(dataloader), accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "optimizer = optim.Adam(bilstm_model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_acc': []\n",
    "}\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "print(\"Training Bidirectional LSTM Model\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"\\\\nEpoch {epoch+1}/{N_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(bilstm_model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc, _, _ = evaluate(bilstm_model, test_loader, criterion, device)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(bilstm_model.state_dict(), 'bilstm_best.pt')\n",
    "        print(f\" Saved best model (Acc: {best_acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"Training Complete! Best Test Accuracy: {best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e28e607",
   "metadata": {},
   "source": [
    "## Part 5: Visualization và Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, N_EPOCHS + 1)\n",
    "\n",
    "# Loss\n",
    "ax = axes[0]\n",
    "ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "ax.plot(epochs, history['test_loss'], 'r-', label='Test Loss', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training & Test Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[1]\n",
    "ax.plot(epochs, [acc*100 for acc in history['train_acc']], 'b-', label='Train Acc', linewidth=2)\n",
    "ax.plot(epochs, [acc*100 for acc in history['test_acc']], 'r-', label='Test Acc', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Training & Test Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('bilstm_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "bilstm_model.load_state_dict(torch.load('bilstm_best.pt'))\n",
    "_, test_acc, predictions, true_labels = evaluate(bilstm_model, test_loader, criterion, device)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.title(f'Confusion Matrix (Accuracy: {test_acc*100:.2f}%)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('bilstm_confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c8c42",
   "metadata": {},
   "source": [
    "## Part 6: Comparison with Unidirectional LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unidirectional LSTM for comparison\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Unidirectional LSTM\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
    "                 n_layers=2, dropout=0.5, pad_idx=0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        # Unidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers=n_layers,\n",
    "            batch_first=True, bidirectional=False,  # Not bidirectional\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  # Only hidden_dim (not *2)\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = pack_padded_sequence(\n",
    "            embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        final_hidden = hidden[-1]  # Only last layer\n",
    "        output = self.dropout(final_hidden)\n",
    "        output = self.fc(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output.squeeze(1)\n",
    "\n",
    "# Create and train LSTM\n",
    "lstm_model = LSTMClassifier(\n",
    "    VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "    N_LAYERS, DROPOUT, PAD_IDX\n",
    ").to(device)\n",
    "\n",
    "print(\"Model Comparison\")\n",
    "print(f\"BiLSTM parameters: {sum(p.numel() for p in bilstm_model.parameters()):,}\")\n",
    "print(f\"LSTM parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "print(f\"\\\\nBiLSTM has ~{sum(p.numel() for p in bilstm_model.parameters()) / sum(p.numel() for p in lstm_model.parameters()):.2f}x more parameters\")\n",
    "\n",
    "# Train LSTM\n",
    "print(\"Training Unidirectional LSTM\")\n",
    "\n",
    "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "lstm_history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"\\\\nEpoch {epoch+1}/{N_EPOCHS}\")\n",
    "    train_loss, train_acc = train_epoch(lstm_model, train_loader, lstm_optimizer, criterion, device)\n",
    "    test_loss, test_acc, _, _ = evaluate(lstm_model, test_loader, criterion, device)\n",
    "    \n",
    "    lstm_history['train_loss'].append(train_loss)\n",
    "    lstm_history['train_acc'].append(train_acc)\n",
    "    lstm_history['test_loss'].append(test_loss)\n",
    "    lstm_history['test_acc'].append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare BiLSTM vs LSTM\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, N_EPOCHS + 1)\n",
    "\n",
    "# Test Loss comparison\n",
    "ax = axes[0]\n",
    "ax.plot(epochs, history['test_loss'], 'b-', label='BiLSTM', linewidth=2, marker='o')\n",
    "ax.plot(epochs, lstm_history['test_loss'], 'r-', label='LSTM', linewidth=2, marker='s')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Test Loss', fontsize=12)\n",
    "ax.set_title('Test Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Test Accuracy comparison\n",
    "ax = axes[1]\n",
    "ax.plot(epochs, [acc*100 for acc in history['test_acc']], 'b-', \n",
    "        label='BiLSTM', linewidth=2, marker='o')\n",
    "ax.plot(epochs, [acc*100 for acc in lstm_history['test_acc']], 'r-', \n",
    "        label='LSTM', linewidth=2, marker='s')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('bilstm_vs_lstm.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"FINAL COMPARISON SUMMARY\")\n",
    "print(f\"{'Model':<15} {'Parameters':>15} {'Best Test Acc':>15}\")\n",
    "print(f\"{'BiLSTM':<15} {sum(p.numel() for p in bilstm_model.parameters()):>15,} \"\n",
    "      f\"{max(history['test_acc'])*100:>14.2f}%\")\n",
    "print(f\"{'LSTM':<15} {sum(p.numel() for p in lstm_model.parameters()):>15,} \"\n",
    "      f\"{max(lstm_history['test_acc'])*100:>14.2f}%\")\n",
    "\n",
    "improvement = (max(history['test_acc']) - max(lstm_history['test_acc'])) * 100\n",
    "print(f\"\\\\n BiLSTM improvement: +{improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149c4a3",
   "metadata": {},
   "source": [
    "## Part 7: Prediction on Custom Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f45730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, text, vocab, device):\n",
    "    \"\"\"Predict sentiment for a single text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess\n",
    "    indices = vocab.text_to_indices(text)\n",
    "    sequence = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    length = torch.tensor([len(indices)]).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        prediction = model(sequence, length)\n",
    "    \n",
    "    prob = prediction.item()\n",
    "    sentiment = \"Positive\" if prob >= 0.5 else \"Negative\"\n",
    "    confidence = prob if prob >= 0.5 else 1 - prob\n",
    "    \n",
    "    return sentiment, confidence\n",
    "\n",
    "# Test with custom reviews\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! I loved every minute of it.\",\n",
    "    \"Terrible film. Waste of time and money. Do not watch.\",\n",
    "    \"The acting was good but the plot was confusing and boring.\",\n",
    "    \"Best movie I've seen this year! Highly recommended!\",\n",
    "    \"Not bad, but not great either. Just average.\"\n",
    "]\n",
    "\n",
    "print(\"Sample Predictions\")\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    sentiment, confidence = predict_sentiment(bilstm_model, review, vocab, device)\n",
    "    \n",
    "    print(f\"\\\\n[{i}] Review: {review}\")\n",
    "    print(f\"    Prediction: {sentiment} (confidence: {confidence*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
