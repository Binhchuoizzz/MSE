{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NLP501 - NATURAL LANGUAGE PROCESSING\n",
        "\n",
        "# EXTRA LAB 02\n",
        "## Multi-Algorithm Text Classification\n",
        "## Movie Review Sentiment Analysis\n",
        "\n",
        "- **Language:** Python 3.8+\n",
        "- **Tools:** Jupyter Notebook, NumPy, NLTK, scikit-learn\n",
        "- **Dataset:** IMDB Movie Reviews\n",
        "- **Objective:** Compare multiple classification algorithms\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this exercise, you will:\n",
        "1. Load and explore a real movie review dataset\n",
        "2. Implement comprehensive text preprocessing\n",
        "3. Extract different types of features (Bag-of-Words, TF-IDF, N-grams)\n",
        "4. Train and evaluate **multiple classifiers**:\n",
        "   - Naive Bayes (Multinomial & Bernoulli)\n",
        "   - Logistic Regression\n",
        "   - Support Vector Machine (SVM)\n",
        "5. Compare performance using various metrics\n",
        "6. Perform error analysis and model interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "### 1.1. Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install numpy pandas nltk scikit-learn matplotlib seaborn wordcloud\n",
        "\n",
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Import Libraries\n",
        "\n",
        "Import all necessary libraries for your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import all necessary libraries\n",
        "# Hints: numpy, pandas, nltk, sklearn, matplotlib, seaborn, etc.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add more imports as needed\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Exploration\n",
        "\n",
        "### Task 1: Load the IMDB Movie Reviews Dataset\n",
        "\n",
        "The dataset contains 2,000 movie reviews (1,000 positive, 1,000 negative) from the NLTK corpus.\n",
        "\n",
        "**Requirements:**\n",
        "1. Load reviews from `nltk.corpus.movie_reviews`\n",
        "2. Create a list of texts and corresponding labels\n",
        "3. Convert to a pandas DataFrame with columns: `text`, `label`, `length`\n",
        "4. Shuffle the dataset\n",
        "5. Display basic statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load movie reviews dataset\n",
        "# Hint: Use nltk.corpus.movie_reviews.fileids() and movie_reviews.raw(fileid)\n",
        "\n",
        "from nltk.corpus import movie_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2: Exploratory Data Analysis (EDA)\n",
        "\n",
        "**Requirements:**\n",
        "1. Display dataset shape and first few rows\n",
        "2. Check class distribution (positive vs negative)\n",
        "3. Calculate and display statistics:\n",
        "   - Average review length\n",
        "   - Min/Max review length\n",
        "   - Median review length per class\n",
        "4. Create visualizations:\n",
        "   - Distribution of review lengths (histogram)\n",
        "   - Class distribution (bar plot)\n",
        "   - Box plot of lengths by class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Perform EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Preprocessing\n",
        "\n",
        "### Task 3: Implement Comprehensive Preprocessing\n",
        "\n",
        "Create a preprocessing pipeline that:\n",
        "1. Converts to lowercase\n",
        "2. Removes special characters and numbers\n",
        "3. Tokenizes text\n",
        "4. Removes stopwords\n",
        "5. Applies lemmatization (optional: use stemming instead)\n",
        "6. Filters out very short tokens (< 3 characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement preprocessing functions\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_text_basic(text):\n",
        "    \"\"\"\n",
        "    Basic preprocessing: lowercase, tokenize, remove stopwords\n",
        "    \n",
        "    Args:\n",
        "        text (str): Input text\n",
        "    Returns:\n",
        "        str: Preprocessed text (space-separated tokens)\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "def preprocess_text_advanced(text):\n",
        "    \"\"\"\n",
        "    Advanced preprocessing: + lemmatization, remove numbers/special chars\n",
        "    \n",
        "    Args:\n",
        "        text (str): Input text\n",
        "    Returns:\n",
        "        str: Preprocessed text (space-separated tokens)\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test your preprocessing functions\n",
        "sample_text = \"This movie is AMAZING!!! I've watched it 3 times. Best film of 2023! :)\"\n",
        "\n",
        "print(\"Original:\", sample_text)\n",
        "print(\"Basic:\", preprocess_text_basic(sample_text))\n",
        "print(\"Advanced:\", preprocess_text_advanced(sample_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Apply preprocessing to entire dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Extraction\n",
        "\n",
        "### Task 4: Extract Multiple Types of Features\n",
        "\n",
        "Implement feature extraction using scikit-learn:\n",
        "\n",
        "**A. Bag-of-Words (CountVectorizer)**\n",
        "- Parameters to experiment with: `max_features`, `min_df`, `max_df`\n",
        "\n",
        "**B. TF-IDF (TfidfVectorizer)**\n",
        "- Compare with Bag-of-Words\n",
        "\n",
        "**C. N-grams**\n",
        "- Unigrams (1-gram)\n",
        "- Bigrams (2-gram)\n",
        "- Trigrams (3-gram)\n",
        "- Combined (1,2)-grams or (1,3)-grams\n",
        "\n",
        "**Requirements:**\n",
        "1. Split data into train/test (80/20)\n",
        "2. Create at least **4 different feature representations**\n",
        "3. Print shape and sample features for each representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Split data into train/test sets\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Feature Extraction Method 1 - Bag of Words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Feature Extraction Method 2 - TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Feature Extraction Method 3 - Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Feature Extraction Method 4 - Combined N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training and Evaluation\n",
        "\n",
        "### Task 5: Train Multiple Classifiers\n",
        "\n",
        "Train and evaluate the following algorithms:\n",
        "\n",
        "1. **Multinomial Naive Bayes**\n",
        "2. **Bernoulli Naive Bayes**\n",
        "3. **Logistic Regression**\n",
        "4. **Linear SVM (LinearSVC)**\n",
        "5. **Bonus:** Random Forest or any other classifier\n",
        "\n",
        "**For each classifier:**\n",
        "- Train on ALL feature types (BoW, TF-IDF, bigrams, n-grams)\n",
        "- Calculate metrics: Accuracy, Precision, Recall, F1-score\n",
        "- Record training time\n",
        "- Store results in a structured format (dictionary or DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import classifiers\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a function to train and evaluate a model\n",
        "\n",
        "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name, feature_name):\n",
        "    \"\"\"\n",
        "    Train a model and return evaluation metrics\n",
        "    \n",
        "    Args:\n",
        "        model: sklearn classifier\n",
        "        X_train, X_test: feature matrices\n",
        "        y_train, y_test: labels\n",
        "        model_name: name of the model (str)\n",
        "        feature_name: name of feature type (str)\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dictionary containing all metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Train all models on all feature types\n",
        "\n",
        "results = []\n",
        "\n",
        "models = {\n",
        "    'Multinomial NB': MultinomialNB(),\n",
        "    'Bernoulli NB': BernoulliNB(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Linear SVM': LinearSVC(max_iter=1000)\n",
        "}\n",
        "\n",
        "feature_sets = {\n",
        "    'Bag-of-Words': (X_train_bow, X_test_bow),\n",
        "    'TF-IDF': (X_train_tfidf, X_test_tfidf),\n",
        "    'Bigrams': (X_train_bigram, X_test_bigram),\n",
        "    'N-grams': (X_train_ngram, X_test_ngram)\n",
        "}\n",
        "\n",
        "# Loop through all combinations of models and features\n",
        "# Use train_and_evaluate function\n",
        "# Append results to list\n",
        "\n",
        "# Convert results to DataFrame for easy analysis\n",
        "# results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 6: Results Analysis and Visualization\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a comprehensive results table showing all metrics\n",
        "2. Identify the best model for each feature type\n",
        "3. Identify the best overall model\n",
        "4. Create visualizations:\n",
        "   - Bar chart comparing accuracy across models and features\n",
        "   - Heatmap of F1-scores (models Ã— features)\n",
        "   - Training time comparison\n",
        "5. Display confusion matrix for the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display comprehensive results table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Find best models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create visualization 1 - Accuracy comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create visualization 2 - F1-score \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display confusion matrix for best model\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Retrain best model and display confusion matrix with visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Error Analysis\n",
        "\n",
        "### Task 7: Analyze Misclassifications\n",
        "\n",
        "**Requirements:**\n",
        "1. Find all misclassified examples from the best model\n",
        "2. Categorize errors:\n",
        "   - False Positives (predicted positive, actually negative)\n",
        "   - False Negatives (predicted negative, actually positive)\n",
        "3. Display at least 10 examples from each category\n",
        "4. Analyze patterns:\n",
        "   - Are there common words in misclassified reviews?\n",
        "   - Is there a relationship between review length and errors?\n",
        "5. Create visualizations:\n",
        "   - Length distribution of correct vs incorrect predictions\n",
        "   - Word cloud of misclassified reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Get predictions from best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Find and categorize misclassifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Analyze error patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualization - Length distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualization - Word cloud of misclassified reviews\n",
        "from wordcloud import WordCloud\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
