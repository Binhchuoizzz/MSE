{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NLP501 - NATURAL LANGUAGE PROCESSING\n",
        "\n",
        "# LAB 02\n",
        "## Naïve Bayes Classifier\n",
        "## Sentiment Analysis\n",
        "\n",
        "- **Language:** Python 3.8+\n",
        "- **Tools:** Jupyter Notebook, NumPy, NLTK\n",
        "- **Dataset:** Twitter Sentiment (NLTK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prerequisites\n",
        "\n",
        "### 2.1. Required Knowledge\n",
        "\n",
        "- Understanding of Naïve Bayes theory from Session 02 lecture\n",
        "- Basic Python: functions, classes, dictionaries\n",
        "- Basic NumPy: array operations\n",
        "\n",
        "### 2.2. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install numpy nltk scikit-learn matplotlib\n",
        "\n",
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Environment Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# Load data\n",
        "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "print(f'Positive tweets: {len(pos_tweets)}')\n",
        "print(f'Negative tweets: {len(neg_tweets)}')\n",
        "print(f'Sample: {pos_tweets[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Introduction\n",
        "\n",
        "### 3.1. Twitter Sentiment Dataset\n",
        "\n",
        "The dataset consists of 10,000 manually labeled tweets:\n",
        "- 5,000 positive tweets (positive sentiment)\n",
        "- 5,000 negative tweets (negative sentiment)\n",
        "\n",
        "### 3.2. Data Examples\n",
        "\n",
        "**Positive examples:**\n",
        "- \"I love this movie, it's amazing! :)\"\n",
        "- \"What a beautiful day, feeling great!\"\n",
        "\n",
        "**Negative examples:**\n",
        "- \"This is terrible, worst experience ever :(\"\n",
        "- \"So disappointed, total waste of time\"\n",
        "\n",
        "### 3.3. Data Split\n",
        "\n",
        "We will split the data into:\n",
        "- **Training set:** 80% (4,000 positive + 4,000 negative = 8,000 tweets)\n",
        "- **Test set:** 20% (1,000 positive + 1,000 negative = 2,000 tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_pos = pos_tweets[:4000]\n",
        "train_neg = neg_tweets[:4000]\n",
        "test_pos = pos_tweets[4000:]\n",
        "test_neg = neg_tweets[4000:]\n",
        "\n",
        "# Create labels\n",
        "train_x = train_pos + train_neg\n",
        "train_y = [1] * len(train_pos) + [0] * len(train_neg)\n",
        "\n",
        "test_x = test_pos + test_neg\n",
        "test_y = [1] * len(test_pos) + [0] * len(test_neg)\n",
        "\n",
        "print(f'Training: {len(train_x)} tweets')\n",
        "print(f'Testing: {len(test_x)} tweets')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implementation\n",
        "\n",
        "### 4.1. Step 1: Text Preprocessing\n",
        "\n",
        "Before building the model, we need to preprocess the text.\n",
        "\n",
        "#### Task 1: Implement Preprocessing Function\n",
        "\n",
        "Complete the `preprocess_tweet()` function to:\n",
        "1. Remove URLs, mentions, hashtags\n",
        "2. Convert to lowercase\n",
        "3. Tokenize\n",
        "4. Remove stopwords and punctuation\n",
        "5. Return list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    '''\n",
        "    Preprocess tweet and return list of tokens\n",
        "    \n",
        "    Args:\n",
        "        tweet (str): Original tweet\n",
        "    Returns:\n",
        "        list: List of processed tokens\n",
        "    '''\n",
        "    # Remove URLs (http, https)\n",
        "    tweet = re.sub(r'https?://\\S+', '', tweet)\n",
        "    \n",
        "    # Remove mentions (@username)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    \n",
        "    # Remove hashtag symbols\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    # Tokenize\n",
        "    tokenizer = TweetTokenizer()\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    \n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "    tokens = [t for t in tokens if t not in stop_words and t not in punctuation]\n",
        "    \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Preprocessing\n",
        "\n",
        "Expected result:\n",
        "```python\n",
        ">>> tweet = \"@user I love this movie! https://example.com #happy\"\n",
        ">>> preprocess_tweet(tweet)\n",
        "['love', 'movie', 'happy']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test preprocessing\n",
        "tweet = \"@user I love this movie! https://example.com #happy\"\n",
        "print(f\"Original: {tweet}\")\n",
        "print(f\"Processed: {preprocess_tweet(tweet)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2. Step 2: Build Vocabulary and Frequency Dictionary\n",
        "\n",
        "The next step is to count word frequencies in each class.\n",
        "\n",
        "#### Task 2: Build Frequency Dictionary\n",
        "\n",
        "Implement the `build_freqs()` function to count occurrences of each (word, label) pair in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_freqs(tweets, labels):\n",
        "    '''\n",
        "    Build frequency dictionary\n",
        "    \n",
        "    Args:\n",
        "        tweets (list): List of tweets\n",
        "        labels (list): List of labels (0 or 1)\n",
        "    Returns:\n",
        "        dict: Dictionary with key=(word, label), value=count\n",
        "    '''\n",
        "    freqs = {}\n",
        "    \n",
        "    for tweet, label in zip(tweets, labels):\n",
        "        tokens = preprocess_tweet(tweet)\n",
        "        \n",
        "        for word in tokens:\n",
        "            key = (word, label) \n",
        "            \n",
        "            if key in freqs:\n",
        "                freqs[key] += 1\n",
        "            else:\n",
        "                freqs[key] = 1\n",
        "    \n",
        "    return freqs\n",
        "\n",
        "# Build frequency dictionary\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "print(f\"Total unique (word, label) pairs: {len(freqs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check some words\n",
        "print(f\"Count of ('happy', 1): {freqs.get(('happy', 1), 0)}\")\n",
        "print(f\"Count of ('happy', 0): {freqs.get(('happy', 0), 0)}\")\n",
        "print(f\"Count of ('sad', 1): {freqs.get(('sad', 1), 0)}\")\n",
        "print(f\"Count of ('sad', 0): {freqs.get(('sad', 0), 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3. Step 3: Compute Probabilities\n",
        "\n",
        "Calculate prior and likelihood probabilities.\n",
        "\n",
        "#### Task 3: Compute Prior and Likelihood\n",
        "\n",
        "Implement the following in the `NaiveBayesClassifier` class:\n",
        "1. `compute_prior()` - calculate P(pos) and P(neg)\n",
        "2. `compute_likelihood()` - calculate P(word|class) with Laplacian smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        '''\n",
        "        Initialize classifier\n",
        "        \n",
        "        Args:\n",
        "            alpha: Smoothing parameter (default=1.0)\n",
        "        '''\n",
        "        self.alpha = alpha\n",
        "        self.log_prior = {}      # log P(class)\n",
        "        self.log_likelihood = {} # log P(word|class)\n",
        "        self.vocab = set()       # Vocabulary\n",
        "    \n",
        "    def train(self, tweets, labels):\n",
        "        '''\n",
        "        Train the model\n",
        "        '''\n",
        "        # Count documents per class\n",
        "        n_pos = sum(labels)\n",
        "        n_neg = len(labels) - n_pos\n",
        "        n_total = len(labels)\n",
        "        \n",
        "        # Compute log prior\n",
        "        self.log_prior[1] = math.log(n_pos / n_total)  # P(pos)\n",
        "        self.log_prior[0] = math.log(n_neg / n_total)  # P(neg)\n",
        "        \n",
        "        # Build frequency dictionary\n",
        "        freqs = build_freqs(tweets, labels)\n",
        "        \n",
        "        # Build vocabulary\n",
        "        self.vocab = set([word for (word, _) in freqs.keys()])\n",
        "        V = len(self.vocab)\n",
        "        \n",
        "        # Count total words per class\n",
        "        total_pos = sum([freqs.get((w, 1), 0) for w in self.vocab])\n",
        "        total_neg = sum([freqs.get((w, 0), 0) for w in self.vocab])\n",
        "        \n",
        "        for word in self.vocab:\n",
        "            freq_pos = freqs.get((word, 1), 0)\n",
        "            freq_neg = freqs.get((word, 0), 0)\n",
        "            \n",
        "            # P(word|pos) with smoothing\n",
        "            p_pos = (freq_pos + self.alpha) / (total_pos + self.alpha * V)\n",
        "            self.log_likelihood[(word, 1)] = math.log(p_pos)\n",
        "            \n",
        "            p_neg = (freq_neg + self.alpha) / (total_neg + self.alpha * V)\n",
        "            self.log_likelihood[(word, 0)] = math.log(p_neg)\n",
        "        \n",
        "        print(f'Vocabulary size: {V}')\n",
        "        print(f'Training complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4. Step 4: Prediction\n",
        "\n",
        "Implement prediction function using log-likelihood.\n",
        "\n",
        "#### Task 4: Implement Predict Method\n",
        "\n",
        "Complete the `predict_single()` and `predict()` methods in the `NaiveBayesClassifier` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add prediction methods to the NaiveBayesClassifier class\n",
        "\n",
        "def predict_single(self, tweet):\n",
        "    '''\n",
        "    Predict for a single tweet\n",
        "    \n",
        "    Args:\n",
        "        tweet (str): Tweet to classify\n",
        "    Returns:\n",
        "        int: 1 (positive) or 0 (negative)\n",
        "    '''\n",
        "    # Preprocess\n",
        "    tokens = preprocess_tweet(tweet)\n",
        "    \n",
        "    # Initialize scores with log prior\n",
        "    score_pos = self.log_prior[1]\n",
        "    score_neg = self.log_prior[0]\n",
        "    \n",
        "    # Add log likelihood for each word\n",
        "    for word in tokens:\n",
        "        if word in self.vocab:\n",
        "            score_pos += self.log_likelihood[(word, 1)]\n",
        "            score_neg += self.log_likelihood[(word, 0)]\n",
        "    \n",
        "    # Return class with higher score\n",
        "    if score_pos > score_neg:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def predict(self, tweets):\n",
        "    '''\n",
        "    Predict for multiple tweets\n",
        "    '''\n",
        "    return [self.predict_single(t) for t in tweets]\n",
        "\n",
        "NaiveBayesClassifier.predict_single = predict_single\n",
        "NaiveBayesClassifier.predict = predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5. Step 5: Model Evaluation\n",
        "\n",
        "Evaluate model performance with metrics.\n",
        "\n",
        "#### Task 5: Compute Evaluation Metrics\n",
        "\n",
        "Implement functions to calculate: accuracy, precision, recall, F1-score from confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    '''\n",
        "    Evaluate model\n",
        "    \n",
        "    Args:\n",
        "        y_true: Ground truth labels\n",
        "        y_pred: Predicted labels\n",
        "    Returns:\n",
        "        dict: Dictionary containing metrics\n",
        "    '''\n",
        "    # Compute confusion matrix\n",
        "    tp = sum([1 for t, p in zip(y_true, y_pred) if t == 1 and p == 1])\n",
        "    tn = sum([1 for t, p in zip(y_true, y_pred) if t == 0 and p == 0])\n",
        "    fp = sum([1 for t, p in zip(y_true, y_pred) if t == 0 and p == 1])\n",
        "    fn = sum([1 for t, p in zip(y_true, y_pred) if t == 1 and p == 0])\n",
        "    \n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)  \n",
        "    \n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    \n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    \n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': [[tn, fp], [fn, tp]]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Complete Model Training and Evaluation\n",
        "\n",
        "### 5.1. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train classifier\n",
        "clf = NaiveBayesClassifier(alpha=1.0)\n",
        "clf.train(train_x, train_y)\n",
        "\n",
        "# Predict on test set\n",
        "predictions = clf.predict(test_x)\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate(test_y, predictions)\n",
        "print(f\"\\n=== Results ===\")\n",
        "print(f\"Accuracy:  {results['accuracy']:.4f}\")\n",
        "print(f\"Precision: {results['precision']:.4f}\")\n",
        "print(f\"Recall:    {results['recall']:.4f}\")\n",
        "print(f\"F1-score:  {results['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2. Expected Results\n",
        "\n",
        "### 5.3. Error Analysis\n",
        "\n",
        "Let's examine some misclassified examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find misclassified cases\n",
        "errors = []\n",
        "for i, (tweet, true_label, pred_label) in enumerate(zip(test_x, test_y, predictions)):\n",
        "    if true_label != pred_label:\n",
        "        errors.append({\n",
        "            'tweet': tweet,\n",
        "            'true': 'positive' if true_label == 1 else 'negative',\n",
        "            'pred': 'positive' if pred_label == 1 else 'negative'\n",
        "        })\n",
        "\n",
        "print(f'\\n=== Misclassified Examples ({len(errors)} total) ===')\n",
        "for i, err in enumerate(errors[:5]):\n",
        "    print(f\"\\n[{i+1}] Tweet: {err['tweet'][:80]}...\")\n",
        "    print(f\"    True: {err['true']}, Predicted: {err['pred']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. More Tasks\n",
        "\n",
        "### Task 6A: Compare with sklearn\n",
        "\n",
        "Use `MultinomialNB` from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement sklearn comparison\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create feature vectors\n",
        "vectorizer = CountVectorizer(preprocessor=lambda x: ' '.join(preprocess_tweet(x)))\n",
        "X_train_vec = vectorizer.fit_transform(train_x)\n",
        "X_test_vec = vectorizer.transform(test_x)\n",
        "\n",
        "# Train sklearn NB\n",
        "sklearn_clf = MultinomialNB(alpha=1.0)\n",
        "sklearn_clf.fit(X_train_vec, train_y)\n",
        "\n",
        "# Compare results\n",
        "sklearn_pred = sklearn_clf.predict(X_test_vec)\n",
        "sklearn_results = evaluate(test_y, sklearn_pred)\n",
        "\n",
        "print('\\n=== Comparison ===')\n",
        "print(f\"Your implementation:  {results['accuracy']:.4f}\")\n",
        "print(f\"sklearn:              {sklearn_results['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 6B: Experiment with Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alphas = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "accuracies = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    clf_temp = NaiveBayesClassifier(alpha=alpha)\n",
        "    clf_temp.train(train_x, train_y)\n",
        "    pred_temp = clf_temp.predict(test_x)\n",
        "    acc = evaluate(test_y, pred_temp)['accuracy']\n",
        "    accuracies.append(acc)\n",
        "    print(f'alpha={alpha:.2f}: accuracy={acc:.4f}')\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(alphas, accuracies, 'bo-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Alpha (Smoothing Parameter)', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Effect of Laplacian Smoothing on Accuracy', fontsize=14)\n",
        "plt.xscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('smoothing_effect.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 6C: Analyze Important Words\n",
        "\n",
        "Find and display top 20 words with highest and lowest lambda (log-likelihood ratio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze important words\n",
        "# Compute lambda for each word\n",
        "lambdas = {}\n",
        "for word in clf.vocab:\n",
        "    log_pos = clf.log_likelihood.get((word, 1), 0)\n",
        "    log_neg = clf.log_likelihood.get((word, 0), 0)\n",
        "    lambdas[word] = log_pos - log_neg\n",
        "\n",
        "# Sort by lambda\n",
        "sorted_words = sorted(lambdas.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print('Top 20 POSITIVE Words (highest lambda):')\n",
        "for i, (word, lam) in enumerate(sorted_words[:20], 1):\n",
        "    print(f'{i:2d}. {word:20s} λ = {lam:7.3f}')\n",
        "\n",
        "print('Top 20 NEGATIVE Words (lowest lambda):')\n",
        "for i, (word, lam) in enumerate(sorted_words[-20:], 1):\n",
        "    print(f'{i:2d}. {word:20s} λ = {lam:7.3f}')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
